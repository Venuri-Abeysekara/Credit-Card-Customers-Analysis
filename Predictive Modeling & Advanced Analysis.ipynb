{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e285dd1d-7d97-468c-827f-11dfd422b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, accuracy_score)\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a6a079-6de6-4267-9a90-ced5e4864066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BankChurners.csv')\n",
    "df['Churn'] = (df['Attrition_Flag'] == 'Attrited Customer').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fa6745-4984-4d17-9699-3d026d2141a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       " **FEATURE ENGINEERING**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       " Creating new predictive features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Definitions**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Engagement Score = Transactions per month\n",
      "   Inactivity Rate = Percentage of year inactive \n",
      "   High Utilization = >70% credit used\n",
      "   Low Transaction = <50 transactions made\n",
      "   Few Products = ≤2 products bought\n",
      "   Declining Spending = Q4 vs Q1 decrease in spending \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       " **New Features - Correlation with Churn:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Engagement_Score          -0.2872\n",
      "   Inactivity_Rate           +0.1524\n",
      "   High_Utilization          -0.0291\n",
      "   Low_Transaction           +0.3909\n",
      "   Few_Products              +0.1532\n",
      "   Declining_Spending        +0.0821\n"
     ]
    }
   ],
   "source": [
    "# Creating new features that might predict churn\n",
    "display(Markdown(\"\\n **FEATURE ENGINEERING**\"))\n",
    "display(Markdown(\"\\n Creating new predictive features\"))\n",
    "\n",
    "\n",
    "# 1. Engagement Score (transactions per month on book)\n",
    "df['Engagement_Score'] = df['Total_Trans_Ct'] / df['Months_on_book']\n",
    "\n",
    "# 2. Inactivity Rate\n",
    "df['Inactivity_Rate'] = df['Months_Inactive_12_mon'] / 12\n",
    "\n",
    "# 3. Credit Utilization Category\n",
    "df['High_Utilization'] = (df['Avg_Utilization_Ratio'] > 0.7).astype(int)\n",
    "\n",
    "# 4. Low Transaction Flag\n",
    "df['Low_Transaction'] = (df['Total_Trans_Ct'] < 50).astype(int)\n",
    "\n",
    "# 5. Product Concentration (fewer products = higher risk)\n",
    "df['Few_Products'] = (df['Total_Relationship_Count'] <= 2).astype(int)\n",
    "\n",
    "# 6. Spending Momentum (transaction change Q4 vs Q1)\n",
    "df['Declining_Spending'] = (df['Total_Amt_Chng_Q4_Q1'] < 0.7).astype(int)\n",
    "\n",
    "display(Markdown(\"**Definitions**\"))\n",
    "print(\"   Engagement Score = Transactions per month\")\n",
    "print(\"   Inactivity Rate = Percentage of year inactive \")\n",
    "print(\"   High Utilization = >70% credit used\")\n",
    "print(\"   Low Transaction = <50 transactions made\")\n",
    "print(\"   Few Products = ≤2 products bought\")\n",
    "print(\"   Declining Spending = Q4 vs Q1 decrease in spending \\n\")\n",
    "\n",
    "\n",
    "# Correlation of new features\n",
    "display(Markdown(\"\\n **New Features - Correlation with Churn:**\"))\n",
    "\n",
    "new_features = ['Engagement_Score', 'Inactivity_Rate', 'High_Utilization',\n",
    "                'Low_Transaction', 'Few_Products', 'Declining_Spending']\n",
    "\n",
    "for feature in new_features:\n",
    "    corr = df[[feature, 'Churn']].corr().iloc[0, 1]\n",
    "    print(f\"   {feature:<25} {corr:>+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e372064-5394-4a9c-ae8a-6107feed8dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       " **PREPARING DATA FOR MACHINE LEARNING**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables\n",
      "    Encoded Gender\n",
      "    Encoded Education_Level\n",
      "    Encoded Marital_Status\n",
      "    Encoded Income_Category\n",
      "    Encoded Card_Category\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\\n **PREPARING DATA FOR MACHINE LEARNING**\"))\n",
    "\n",
    "# Encoding categorical variables\n",
    "print(\"Encoding categorical variables\")\n",
    "categorical_cols = ['Gender', 'Education_Level', 'Marital_Status', \n",
    "                    'Income_Category', 'Card_Category']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col + '_Encoded'] = le.fit_transform(df[col])\n",
    "    print(f\"    Encoded {col}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dddb7e5e-eee6-44af-8f2b-1a6b242f4d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features for prediction\n",
      "   Total features selected: 22\n",
      "      - Original: 11\n",
      "      - Categorical (encoded): 5\n",
      "      - Engineered: 6\n"
     ]
    }
   ],
   "source": [
    "# Selecting features for modeling\n",
    "print(\"Selecting features for prediction\")\n",
    "\n",
    "# Original features\n",
    "original_features = ['Customer_Age', 'Dependent_count', 'Months_on_book',\n",
    "                     'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "                     'Contacts_Count_12_mon', 'Credit_Limit', \n",
    "                     'Total_Revolving_Bal', 'Total_Trans_Amt', \n",
    "                     'Total_Trans_Ct', 'Avg_Utilization_Ratio']\n",
    "\n",
    "# Encoded categorical features\n",
    "encoded_features = [col + '_Encoded' for col in categorical_cols]\n",
    "\n",
    "# New engineered features\n",
    "engineered_features = ['Engagement_Score', 'Inactivity_Rate', \n",
    "                       'High_Utilization', 'Low_Transaction', \n",
    "                       'Few_Products', 'Declining_Spending']\n",
    "\n",
    "# Combining all features\n",
    "all_features = original_features + encoded_features + engineered_features\n",
    "\n",
    "print(f\"   Total features selected: {len(all_features)}\")\n",
    "print(f\"      - Original: {len(original_features)}\")\n",
    "print(f\"      - Categorical (encoded): {len(encoded_features)}\")\n",
    "print(f\"      - Engineered: {len(engineered_features)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0495d4-51e4-4653-bc8d-3a609c6085e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data (80% for training, 20% for testing)\n",
      "\n",
      "  Training set:\n",
      "    Training set: 8,101 customers\n",
      "    Churn rate in train: 16.07%\n",
      "\n",
      "  Testing set:\n",
      "    Testing set: 2,026 customers\n",
      "    Churn rate in test: 16.04%\n"
     ]
    }
   ],
   "source": [
    "# Preparing X and y\n",
    "X = df[all_features]\n",
    "y = df['Churn']\n",
    "\n",
    "# Split data\n",
    "print(\"Splitting data (80% for training, 20% for testing)\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\n  Training set:\")\n",
    "print(f\"    Training set: {len(X_train):,} customers\")\n",
    "print(f\"    Churn rate in train: {y_train.mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\n  Testing set:\")\n",
    "print(f\"    Testing set: {len(X_test):,} customers\")\n",
    "print(f\"    Churn rate in test: {y_test.mean()*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc099d9e-ab50-40c5-89d9-808799f5d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing features\n",
      "   Features standardized (mean=0, std=1)\n"
     ]
    }
   ],
   "source": [
    "# Standardizing features\n",
    "print(\"Standardizing features\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"   Features standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c57b484e-5959-4960-97f6-a49482eed3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       " **MODEL 01: LOGISTIC REGRESSION**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression\n",
    "display(Markdown(\"\\n **MODEL 01: LOGISTIC REGRESSION**\"))\n",
    "\n",
    "# Training model\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc87190b-166e-4f99-b55c-033d5064be1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions\n",
      "\n",
      "Model Performance:\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.8968 (89.68%)\n",
      "\n",
      "AUC Score: 0.9033\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**EXCELLENT - Outstanding Predictive Power!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.91      0.97      0.94      1701\n",
      "     Churned       0.77      0.51      0.61       325\n",
      "\n",
      "    accuracy                           0.90      2026\n",
      "   macro avg       0.84      0.74      0.78      2026\n",
      "weighted avg       0.89      0.90      0.89      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print(\"\\nMaking predictions\")\n",
    "y_pred_log = log_model.predict(X_test_scaled)\n",
    "y_pred_prob_log = log_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_log)\n",
    "auc = roc_auc_score(y_test, y_pred_prob_log)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"\\nAUC Score: {auc:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "if auc > 0.90:\n",
    "    display(Markdown(\"**EXCELLENT - Outstanding Predictive Power!**\"))\n",
    "elif auc > 0.80:\n",
    "    display(Markdown(\"**VERY GOOD - Strong Predictive Ability!**\"))\n",
    "elif auc > 0.70:\n",
    "     display(Markdown(\"**GOOD - Decent Predictive Performance**\"))\n",
    "else:\n",
    "    display(Markdown(\"**FAIR - Needs Improvement**\"))\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_log, \n",
    "                          target_names=['Retained', 'Churned']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d94be276-daba-44f3-b193-b2f30a5d6b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**TOP 15 MOST IMPORTANT FEATURES AND THEIR COEFFICIENT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total_Trans_Ct                      2.3628\n",
      "   Total_Trans_Amt                     1.3120\n",
      "   Few_Products                        0.6571\n",
      "   Total_Revolving_Bal                 0.6479\n",
      "   Contacts_Count_12_mon               0.6301\n",
      "   Avg_Utilization_Ratio               0.5297\n",
      "   High_Utilization                    0.4636\n",
      "   Gender_Encoded                      0.3588\n",
      "   Engagement_Score                    0.2850\n",
      "   Total_Relationship_Count            0.2794\n",
      "   Inactivity_Rate                     0.2550\n",
      "   Months_Inactive_12_mon              0.2550\n",
      "   Months_on_book                      0.1981\n",
      "   Marital_Status_Encoded              0.1964\n",
      "   Dependent_count                     0.1946\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "display(Markdown(\"**TOP 15 MOST IMPORTANT FEATURES AND THEIR COEFFICIENT:**\"))\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Coefficient': np.abs(log_model.coef_[0])\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "for i, row in feature_importance.head(15).iterrows():\n",
    "    print(f\"   {row['Feature']:<35} {row['Coefficient']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "391ce407-1d76-4619-b3fb-b813a4379eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MODEL 02: RANDOM FOREST CLASSIFIER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training Random Forest\n",
    "display(Markdown(\"**MODEL 02: RANDOM FOREST CLASSIFIER**\"))\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, \n",
    "                                  random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"   Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c819f03-a288-4754-9c44-ef155ae9b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions\n",
      "\n",
      "Model performance:\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.9388 (93.88%)\n",
      "\n",
      "AUC Score: 0.9755\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**EXCELLENT - Outstanding Predictive Power!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.95      0.98      0.96      1701\n",
      "     Churned       0.89      0.70      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.92      0.84      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print(\"\\nMaking predictions\")\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nModel performance:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\")\n",
    "print(f\"\\nAUC Score: {auc_rf:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "if auc_rf > 0.90:\n",
    "    display(Markdown(\"**EXCELLENT - Outstanding Predictive Power!**\"))\n",
    "elif auc_rf > 0.80:\n",
    "    display(Markdown(\"**VERY GOOD - Strong Predictive Ability!**\"))\n",
    "elif auc_rf > 0.70:\n",
    "    display(Markdown(\"**GOOD - Decent Predictive Performance**\"))\n",
    "else:\n",
    "    display(Markdown(\"**FAIR - Needs Improvement**\"))\n",
    "\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                          target_names=['Retained', 'Churned']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e4465b5-50cb-4c5d-aeb7-7007ba9370d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**TOP 15 MOST IMPORTANT FEATURES AND THEIR IMPORTANCE PERCENTAGE:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total_Trans_Amt                     0.1844 (18.44%)\n",
      "   Total_Trans_Ct                      0.1581 (15.81%)\n",
      "   Total_Revolving_Bal                 0.1129 (11.29%)\n",
      "   Engagement_Score                    0.0822 (8.22%)\n",
      "   Avg_Utilization_Ratio               0.0793 (7.93%)\n",
      "   Low_Transaction                     0.0638 (6.38%)\n",
      "   Total_Relationship_Count            0.0624 (6.24%)\n",
      "   Few_Products                        0.0420 (4.20%)\n",
      "   Credit_Limit                        0.0325 (3.25%)\n",
      "   Contacts_Count_12_mon               0.0300 (3.00%)\n",
      "   Customer_Age                        0.0272 (2.72%)\n",
      "   Months_on_book                      0.0212 (2.12%)\n",
      "   Months_Inactive_12_mon              0.0211 (2.11%)\n",
      "   Inactivity_Rate                     0.0211 (2.11%)\n",
      "   Gender_Encoded                      0.0107 (1.07%)\n",
      "\n",
      "Total_Trans_Amt, is the number one predictor and it accounts for 18.44% of prediction power.\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "display(Markdown(\"**TOP 15 MOST IMPORTANT FEATURES AND THEIR IMPORTANCE PERCENTAGE:**\"))\n",
    "\n",
    "\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for i, row in feature_importance_rf.head(15).iterrows():\n",
    "    # Calculate percentage\n",
    "    importance_pct = row['Importance'] * 100\n",
    "    print(f\"   {row['Feature']:<35} {row['Importance']:.4f} ({importance_pct:.2f}%)\")\n",
    "\n",
    "# Identify the most important feature\n",
    "top_feature = feature_importance_rf.iloc[0]\n",
    "print(f\"\\n{top_feature['Feature']}, is the number one predictor and it accounts for {top_feature['Importance']*100:.2f}% of prediction power.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2137f2a4-8dd2-4680-a180-17609a26d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MODEL COMPARISION**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Vs Random Forest \n"
     ]
    }
   ],
   "source": [
    "# Model comparison\n",
    "display(Markdown(\"**MODEL COMPARISION**\"))\n",
    "print(\"Logistic Regression Vs Random Forest \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e73543-72cc-49bf-9641-8765e28ae36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
